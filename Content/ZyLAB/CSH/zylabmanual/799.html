<?xml version="1.0" encoding="utf-8"?>
<html lang="en-US" xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd" MadCap:onlyLocalStylesheets="True">
    <head>
        <link href="../../../Styles/ADDReview_CSH.css" rel="stylesheet" type="text/css" />
    </head>
    <body>
        <div id="header">
            <p class="heading1">Assisted Review Progress</p>
        </div>
        <p>For each <a href="https://docs.zylab.com/01/ZyLAB/ONE/319.html" target="_blank">issue</a>, view the progress of the <a href="https://docs.zylab.com/01/ZyLAB/ONE/329.html" target="_blank">classifier</a>.      </p>
        <p><b>Issue Configuration</b>
        </p>
        <p>View if the issue is&#160;based on a Random Set, a Query, Existing Tagging or created from Topic Modeling<i>.</i></p>
        <p>View the minimum batch size of the issue.</p>
        <p><b>Delete Issue</b>
        </p>
        <p>Click the&#160;<img src="../../../Storage/zylab-one-manual-publication/new-project-2018-08-20.png" alt="" style="width: 89px; height: 38px;" class="ReduceButtonSize" /> button.
        
        
        
      Please note that if an issue is deleted, tags assigned to documents in the issue are deleted. Also, information about the documents related to the deleted issue will not be shown&#160;in the training rounds report anymore.</p>
        <p><b>Add </b><b>New Training Batch</b>
        </p>
        <p>After reviewing your progress, you can add a <a href="https://docs.zylab.com/01/ZyLAB/ONE/325.html" target="_blank">new training batch</a>&#160;to your issue:</p>
        <p>
            <img src="../../../Storage/zylab-one-manual-publication/new-project-2018-02-13-3.png" id="img_upload_6f57232b-f77d-be00-ab9a-693fcbca5bed" style="width: 235px;height: 42px;" alt="" />
        </p>
        <p><b>View Statistics and Graphs</b>
        </p>
        <p>To view the <a href="https://docs.zylab.com/01/ZyLAB/ONE/322.html" target="_blank">Statistics and Graphs</a>, select (in the bottom left corner of an issue)&#160;<br /><img src="../../../Storage/zylab-one-manual-publication/new-project-2018-07-12.png" alt="" />&#160;</p>
        <p style="font-size: 11pt;"><b style="font-size: 11pt;">Classify Remaining</b>
        </p>
        <p style="font-size: 11pt;">Select Classify Remaining if finding more responsive documents is&#160;not worth the time/cost of (manually) reviewing more documents, and/or&#160;the classifier&#160;is returning good results (the quality of the classifier is determined based on the results of the statistics and graphs).</p>
        <p style="font-size: 11pt;">Set the <a href="https://docs.zylab.com/01/ZyLAB/ONE/779.html" target="_blank">Classifier Threshold Score</a> (with a value larger than 0.0 and smaller than 1.0, default threshold is set at 0.5). Only documents with a <a href="https://docs.zylab.com/01/ZyLAB/ONE/329.html" target="_blank">ranking value</a> higher than (<b>not</b> equal to) the Classifier Threshold Score will be classified and put in the Classification Results (Assisted Review Results field).</p>
        <p>
            <img src="../../../Storage/zylab-one-manual-publication/new-project-2018-07-12-1.png" alt="" /><b><![CDATA[        ]]></b>
        </p>
        <h3>Training Batch Status</h3>
        <p><b>Completed      </b>
        </p>
        <p>Total reviewed documents (Responsive or Not Responsive&#160;Assisted Review&#160;tag applied) of
 
 the Training Batches for this issue.
      
      
      </p>
        <p><b>ToDo
        </b>
        </p>
        <p> Total 
      <i>
       not yet 
      </i>
      reviewed documents of the Training Batch for this issue.
      </p>
        <p> If you request a new training batch, ToDo will only be reset and a new training batch will only be calculated when the following conditions for the issue are met:
</p>
        <ul class="listbullet">
            <li class="listbullet">
        All documents of the initial training set size are reviewed. If not, the request for a new training batch will be ignored. The reviewer has to finish review of the initial training set.
      </li>
            <li class="listbullet">
        The reviewed documents contain at least a Responsive and a Not Responsive document. If not, the Training Batch will be extended, but you will remain in the same training round.
      </li>
        </ul>
        <h3>Training Results</h3>
        <p><b>  Responsive Documents Found
      </b><![CDATA[   ]]></p>
        <p>Documents with Responsive&#160;Assisted Review&#160;tag applied, excluding Validation Set.
    <b><![CDATA[
        ]]></b></p>
        <p><b>Classified as Responsive
      </b><![CDATA[    ]]></p>
        <p>Documents that are classified as responsive by the last trained classifier. Documents that are classified as responsive, are not automatically tagged with Assisted Review tags.&#160; &#160;
    </p>
        <p><b>Classifier Threshold Score&#160;</b>
        </p>
        <p>The Classifier Threshold Score that was used when selecting Classify Remaining.</p>
        <p><b>Training Statistics
      </b>
        </p>
        <p>Precision is a measure of result relevancy, while recall is a measure of how many truly relevant results are returned. High scores for both precision and recall show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).
    <b>&#160;</b></p>
        <p><b>Precision for Recall Goal</b><span class="bodytext"><![CDATA[  ]]></span>
        </p>
        <p>Precision value for the user-defined recall goal in precision recall curve on Training Batch.
    <b><![CDATA[
        ]]></b></p>
        <p><b>Recall Goal
      </b>
        </p>
        <p>User-defined goal.
</p>
        <p><b style="text-decoration-style: initial;text-decoration-color: initial;"> Estimated Current Recall&#160;
      </b><![CDATA[  
      ]]></p>
        <p>The estimated current recall is the total number of reviewed responsive documents in the project (including the reviewed responsive documents of the Validation Set) divided by the estimated number of all responsive documents in the project.
      <b><![CDATA[      
      ]]></b></p>
        <p><b>Validation Set Status
         </b>
        </p>
        <p><b>Completed
    </b>
        </p>
        <p>Total reviewed documents (Responsive or Not Responsive Assisted Review tag applied) of the Validation Set for this issue.&#160;
    <b>&#160;</b></p>
        <p><b>ToDo&#160;
  <br /></b>
        </p>
        <p>Total 
    <i>      not yet
   </i>    reviewed documents of the 
 
 
 Validation Set for this issue.   <b><![CDATA[    ]]></b></p>
        <p><b>Extend Set
  </b>
            <br />
        </p>
        <p>You can extend the Validation Set. Please review the Validation Set completely before extending it. Extend Set will extend Validation Sets&#160;for all project issues.
    <br /></p>
        <p>Click Extend Set and click OK. The size of the Validation Set will be extended with 10% of the current Validation Set (with a minimum of 50 documents). Click Extend Set again to add another 10%.
    <br /></p>
        <p><b>   Validation Set Results
    </b>
        </p>
        <p><b>  Responsive&#160;
      </b><![CDATA[   ]]></p>
        <p>Documents of the Validation Set with Responsive&#160;Assisted Review&#160;tag applied.
    <b><![CDATA[
        ]]></b></p>
        <p><b>Not Responsive
      </b>
        </p>
        <p>Documents of the Validation Set with Not Responsive Assisted Review tag applied.
    </p>
        <p><b>Precision for Recall Goal
      </b><![CDATA[   ]]></p>
        <p>Precision value for the user-defined recall goal in precision recall curve on Validation Set.
    
    <b>&#160;</b></p>
    </body>
</html>