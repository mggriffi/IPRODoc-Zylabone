<?xml version="1.0" encoding="utf-8"?>
<html lang="en-US" xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd" MadCap:onlyLocalStylesheets="True">
    <head>
        <link href="../../../Styles/ADDReview_CSH.css" rel="stylesheet" type="text/css" />
    </head>
    <body>
        <div id="header">
            <p class="heading1">Assisted Review</p>
        </div>
        <h3>Project Actions</h3>
        <p>Once a <a href="https://docs.zylab.com/01/ZyLAB/ONE/1090.html" target="_blank">project</a> has been added,&#160;click 
        <img src="../../../Storage/zylab-one-manual-publication/new-project-2017-10-12-1.png" />
        for all Project Actions.&#160; 
        <br /></p>
        <p>      
        Click&#160;
        <img src="../../../Storage/zylab-one-manual-publication/new-project-2017-10-16.png" />
        to unfold all available projects and select one.
</p>
        <p><b>Add Project
          </b>
        </p>
        <p>      Click 
        <b>
          + Add Project
        </b>
        to open the Create Project Wizard.
        </p>
        <p>       In a project, (subsets of) documents from a matter are reviewed/analyzed.
        </p>
        <p><b>          Add Issue
          </b>
        </p>
        <p>       Click 
        <b>
          + Add Issue
        </b>
        to add a new <a href="https://docs.zylab.com/01/ZyLAB/ONE/319.html" target="_blank">issue</a> to your project.
        </p>
        <p><b>        Recalculate Vectors
          </b>
        </p>
        <p>      Text documents are converted to a document vector representation suitable for the <a href="https://docs.zylab.com/01/ZyLAB/ONE/329.html" target="_blank">classifier</a>. 
                New documents might be added to the matter on which your project was based. To ensure these documents can be used by the Assisted Review process, document vector representation needs to be recalculated.
        
        </p>
        <p><b>         Project Report
          </b>
        </p>
        <p>      Click Project Report to&#160;download a PDF report containing data about the project and general statistics about the classification process at the moment of the report request.
        
      </p>
        <p><b>         Training Rounds Report
          </b>
        </p>
        <p>      Click Training Rounds Report to&#160;download a csv report containing data about the reviewed documents at the moment of the report request. The documents are listed by id number, document name, hash value, file type, issue name, responsiveness (Responsive/Not Responsive), training round number and reason (added, removed, changed).</p>
        <p><b>        Delete Project
          </b>
        </p>
        <p>Click Delete Project to remove it.
        
        
        
      
    <br /></p>
        <p>All information from the project will be deleted, including issues/tags. </p>
        <h3>Assisted Review Progress</h3>
        <p>View the progress of the vector calculation process per <a href="https://docs.zylab.com/01/ZyLAB/ONE/319.html" target="_blank">issue</a>.&#160;</p>
        <p><b>Issue Configuration</b>
        </p>
        <p>View if the issue is&#160;based on a Random Set, a Query, Existing Tagging or created from Topic Modeling<i>.</i></p>
        <p>View the minimum batch size of the issue.&#160;
      </p>
        <p><b>Delete Issue</b>
        </p>
        <p>Click the&#160;<img src="../../../Storage/zylab-one-manual-publication/new-project-2018-08-20.png" alt="" class="ReduceButtonSize" /> button.
        
        
        
      Please note that if an issue is deleted, tags assigned to documents in the issue are deleted. Also, information about the documents related to the deleted issue will not be shown&#160;in the training rounds report anymore.    
        
        </p>
        <p><b>Add New Training Batch</b>
        </p>
        <p>After reviewing your progress, you can add a <a href="https://docs.zylab.com/01/ZyLAB/ONE/325.html" target="_blank">new training batch</a>:</p>
        <p>
            <img src="../../../Storage/zylab-one-manual-publication/new-project-2018-02-13-3.png" style="width: 235px;height: 42px;" alt="" />
            <br />
        </p>
        <p><b>View Statistics and Graphs</b>
        </p>
        <p>To view the <a href="https://docs.zylab.com/01/ZyLAB/ONE/322.html" target="_blank">Statistics and Graphs</a>, select (in the bottom left corner of an issue)&#160;</p>
        <p>
            <img src="../../../Storage/zylab-one-manual-publication/new-project-2018-07-12.png" alt="" />
        </p>
        <p><b>Classify Remaining</b>
        </p>
        <p>Select Classify Remaining if finding more responsive documents is not worth the time/cost of (manually) reviewing more documents, and/or&#160;the classifier&#160;is returning good results (the quality of the classifier is determined based on the results of the statistics and graphs)<span style="font-size: 13.3333px;">.</span></p>
        <p>Set the <a href="https://docs.zylab.com/01/ZyLAB/ONE/779.html" target="_blank">Classifier Threshold Score</a> (with a value larger than 0.0 and smaller than 1.0, default threshold is set at 0.5). Only documents with a <a href="https://docs.zylab.com/01/ZyLAB/ONE/329.html" target="_blank">ranking value</a> higher than (<b>not</b> equal to) the Classifier Threshold Score will be classified and put in the Classification Results (Assisted Review Results field).</p>
        <p>
            <img src="../../../Storage/zylab-one-manual-publication/new-project-2018-07-12-1.png" alt="" style="width: 318px;height: 46.3417px;" />
        </p>
        <h3>        Training Batch Status&#160;
        
</h3>
        <p><b>    Completed</b>
        </p>
        <p>    Total reviewed documents (Responsive or Not Responsive&#160;Assisted Review&#160;tag applied) of
 
 the Training Batches for this issue.
      
      
      <b><![CDATA[
          ]]></b></p>
        <p><b>ToDo
        </b>
        </p>
        <p>      Total 
      <i>
        not yet 
      </i>
      reviewed documents of the Training Batch for this issue.
      </p>
        <p>      If you request a new training batch, ToDo will only be reset and a new training batch will only be calculated when the following conditions for the issue are met:
      
    
    </p>
        <ul class="listbullet">
            <li class="listbullet">
                <p>
        All documents of the initial training set size are reviewed. If not, the request for a new training batch will be ignored. The reviewer has to finish review of the initial training set.
      </p>
            </li>
            <li class="listbullet">
                <p>
        The reviewed documents contain at least a Responsive and a Not Responsive document. If not, the Training Batch will be extended, but you will remain in the same training round.
</p>
            </li>
        </ul>
        <h3>Training Results
      </h3>
        <p><b>    Responsive Documents Found
      </b>
        </p>
        <p>    Documents with Responsive&#160;Assisted Review&#160;tag applied, excluding Validation Set.
    </p>
        <p><b>    Classified as Responsive
      </b>
        </p>
        <p>    Documents that are classified as responsive by the last trained classifier. Documents that are classified as responsive, are not automatically tagged with Assisted Review tags.&#160; &#160;
    </p>
        <p><b>Classifier Threshold Score&#160;</b>
        </p>
        <p>The Classifier Threshold Score that was used when selecting Classify Remaining.</p>
        <h3>     Training Statistics
      </h3>
        <p>
    Precision is a measure of result relevancy, while recall is a measure of how many truly relevant results are returned. High scores for both precision and recall show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).
    <b>&#160;</b></p>
        <p><b>    Precision for Recall Goal
      </b>
        </p>
        <p>Precision value for the user-defined recall goal in precision recall curve on Training Batch.
    <b><span style="color: #999999;"><![CDATA[
        ]]></span></b></p>
        <p><b>Recall Goal
      </b> </p>
        <p>   User-defined goal.
    </p>
        <p><b style="text-decoration-style: initial;text-decoration-color: initial;">     Estimated Current Recall&#160;
      </b>
        </p>
        <p>    
      The estimated current recall is the total number of reviewed responsive documents in the project (including the reviewed responsive documents of the Validation Set) divided by the estimated number of all responsive documents in the project.
      <b><![CDATA[
]]></b></p>
        <h3>    
      Validation Set Status
    
</h3>
        <p><b> Completed
    </b>
        </p>
        <p>
    Total reviewed documents (Responsive or Not Responsive Assisted Review tag applied) of the Validation Set for this issue.&#160;
    <b>&#160;</b></p>
        <p><b>    ToDo&#160;
  </b><![CDATA[
    ]]></p>
        <p>Total 
    <i>
      not yet
    </i>
    reviewed documents of the 
 
 
 Validation Set for this issue
    <b><![CDATA[
    ]]></b></p>
        <p><b>Extend Set
  </b>
        </p>
        <p>    You can extend the Validation Set. Please review the Validation Set completely before extending it. Extend Set will extend Validation Sets&#160;for all project issues.
    </p>
        <p>    Click Extend Set and click OK. The size of the Validation Set will be extended with 10% of the current Validation Set (with a minimum of 50 documents). Click Extend Set again to add another 10%.
    </p>
        <h3>     Validation Set Results
    </h3>
        <p><b>    Responsive&#160;
      </b>
        </p>
        <p>    Documents of the Validation Set with Responsive&#160;Assisted Review&#160;tag applied.
    <b><![CDATA[
        ]]></b></p>
        <p><b>Not Responsive&#160;
      </b> </p>
        <p>   Documents of the Validation Set with Not Responsive Assisted Review tag applied.
    </p>
        <p><b>    Precision for Recall Goal
      </b>
        </p>
        <p>    Precision value for the user-defined recall goal in precision recall curve on Validation Set.</p>
    </body>
</html>